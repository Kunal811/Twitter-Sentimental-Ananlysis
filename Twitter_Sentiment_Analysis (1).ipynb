{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "x=pd.read_csv('0000000000002747_training_twitter_x_y_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>567900433542488064</td>\n",
       "      <td>negative</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ColeyGirouard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir I am scheduled for the morning, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-17 20:16:29 -0800</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Atlantic Time (Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>569989168903819264</td>\n",
       "      <td>positive</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WalterFaddoul</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir seeing your workers time in and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-23 14:36:22 -0800</td>\n",
       "      <td>Indianapolis, Indiana; USA</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>568089179520954368</td>\n",
       "      <td>positive</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LocalKyle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united Flew ORD to Miami and back and  had gr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-18 08:46:29 -0800</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment    airline airline_sentiment_gold  \\\n",
       "0  567900433542488064          negative  Southwest                    NaN   \n",
       "1  569989168903819264          positive  Southwest                    NaN   \n",
       "2  568089179520954368          positive     United                    NaN   \n",
       "\n",
       "            name negativereason_gold  retweet_count  \\\n",
       "0  ColeyGirouard                 NaN              0   \n",
       "1  WalterFaddoul                 NaN              0   \n",
       "2      LocalKyle                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0  @SouthwestAir I am scheduled for the morning, ...         NaN   \n",
       "1  @SouthwestAir seeing your workers time in and ...         NaN   \n",
       "2  @united Flew ORD to Miami and back and  had gr...         NaN   \n",
       "\n",
       "               tweet_created              tweet_location  \\\n",
       "0  2015-02-17 20:16:29 -0800             Washington D.C.   \n",
       "1  2015-02-23 14:36:22 -0800  Indianapolis, Indiana; USA   \n",
       "2  2015-02-18 08:46:29 -0800                    Illinois   \n",
       "\n",
       "                user_timezone  \n",
       "0      Atlantic Time (Canada)  \n",
       "1  Central Time (US & Canada)  \n",
       "2  Central Time (US & Canada)  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>567900433542488064</td>\n",
       "      <td>negative</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>ColeyGirouard</td>\n",
       "      <td>@SouthwestAir I am scheduled for the morning, ...</td>\n",
       "      <td>2015-02-17 20:16:29 -0800</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Atlantic Time (Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>569989168903819264</td>\n",
       "      <td>positive</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>WalterFaddoul</td>\n",
       "      <td>@SouthwestAir seeing your workers time in and ...</td>\n",
       "      <td>2015-02-23 14:36:22 -0800</td>\n",
       "      <td>Indianapolis, Indiana; USA</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>568089179520954368</td>\n",
       "      <td>positive</td>\n",
       "      <td>United</td>\n",
       "      <td>LocalKyle</td>\n",
       "      <td>@united Flew ORD to Miami and back and  had gr...</td>\n",
       "      <td>2015-02-18 08:46:29 -0800</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>568928195581513728</td>\n",
       "      <td>negative</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>amccarthy19</td>\n",
       "      <td>@SouthwestAir @dultch97 that's horse radish üò§üê¥</td>\n",
       "      <td>2015-02-20 16:20:26 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atlantic Time (Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>568594180014014464</td>\n",
       "      <td>negative</td>\n",
       "      <td>United</td>\n",
       "      <td>J_Okayy</td>\n",
       "      <td>@united so our flight into ORD was delayed bec...</td>\n",
       "      <td>2015-02-19 18:13:11 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10975</th>\n",
       "      <td>569934458364813313</td>\n",
       "      <td>neutral</td>\n",
       "      <td>American</td>\n",
       "      <td>Cottopanama85</td>\n",
       "      <td>@AmericanAir followback</td>\n",
       "      <td>2015-02-23 10:58:58 -0800</td>\n",
       "      <td>ohio,panama</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10976</th>\n",
       "      <td>568564006329434113</td>\n",
       "      <td>positive</td>\n",
       "      <td>United</td>\n",
       "      <td>PaulBEsteves</td>\n",
       "      <td>@united thanks for the help. Wish the phone re...</td>\n",
       "      <td>2015-02-19 16:13:17 -0800</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10977</th>\n",
       "      <td>569643648910028801</td>\n",
       "      <td>negative</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>runfixsteve</td>\n",
       "      <td>@usairways the. Worst. Ever. #dca #customerser...</td>\n",
       "      <td>2015-02-22 15:43:24 -0800</td>\n",
       "      <td>St. Augustine, Florida</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10978</th>\n",
       "      <td>568864981917110272</td>\n",
       "      <td>negative</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>CLChicosky</td>\n",
       "      <td>@nrhodes85: look! Another apology. DO NOT FLY ...</td>\n",
       "      <td>2015-02-20 12:09:15 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10979</th>\n",
       "      <td>568929299350179840</td>\n",
       "      <td>negative</td>\n",
       "      <td>United</td>\n",
       "      <td>JW_Blocker</td>\n",
       "      <td>@united you are by far the worst airline. 4 pl...</td>\n",
       "      <td>2015-02-20 16:24:49 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10980 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id airline_sentiment     airline           name  \\\n",
       "0      567900433542488064          negative   Southwest  ColeyGirouard   \n",
       "1      569989168903819264          positive   Southwest  WalterFaddoul   \n",
       "2      568089179520954368          positive      United      LocalKyle   \n",
       "3      568928195581513728          negative   Southwest    amccarthy19   \n",
       "4      568594180014014464          negative      United        J_Okayy   \n",
       "...                   ...               ...         ...            ...   \n",
       "10975  569934458364813313           neutral    American  Cottopanama85   \n",
       "10976  568564006329434113          positive      United   PaulBEsteves   \n",
       "10977  569643648910028801          negative  US Airways    runfixsteve   \n",
       "10978  568864981917110272          negative  US Airways     CLChicosky   \n",
       "10979  568929299350179840          negative      United     JW_Blocker   \n",
       "\n",
       "                                                    text  \\\n",
       "0      @SouthwestAir I am scheduled for the morning, ...   \n",
       "1      @SouthwestAir seeing your workers time in and ...   \n",
       "2      @united Flew ORD to Miami and back and  had gr...   \n",
       "3         @SouthwestAir @dultch97 that's horse radish üò§üê¥   \n",
       "4      @united so our flight into ORD was delayed bec...   \n",
       "...                                                  ...   \n",
       "10975                            @AmericanAir followback   \n",
       "10976  @united thanks for the help. Wish the phone re...   \n",
       "10977  @usairways the. Worst. Ever. #dca #customerser...   \n",
       "10978  @nrhodes85: look! Another apology. DO NOT FLY ...   \n",
       "10979  @united you are by far the worst airline. 4 pl...   \n",
       "\n",
       "                   tweet_created              tweet_location  \\\n",
       "0      2015-02-17 20:16:29 -0800             Washington D.C.   \n",
       "1      2015-02-23 14:36:22 -0800  Indianapolis, Indiana; USA   \n",
       "2      2015-02-18 08:46:29 -0800                    Illinois   \n",
       "3      2015-02-20 16:20:26 -0800                         NaN   \n",
       "4      2015-02-19 18:13:11 -0800                         NaN   \n",
       "...                          ...                         ...   \n",
       "10975  2015-02-23 10:58:58 -0800                 ohio,panama   \n",
       "10976  2015-02-19 16:13:17 -0800                    Brooklyn   \n",
       "10977  2015-02-22 15:43:24 -0800      St. Augustine, Florida   \n",
       "10978  2015-02-20 12:09:15 -0800                         NaN   \n",
       "10979  2015-02-20 16:24:49 -0800                         NaN   \n",
       "\n",
       "                    user_timezone  \n",
       "0          Atlantic Time (Canada)  \n",
       "1      Central Time (US & Canada)  \n",
       "2      Central Time (US & Canada)  \n",
       "3          Atlantic Time (Canada)  \n",
       "4      Eastern Time (US & Canada)  \n",
       "...                           ...  \n",
       "10975                         NaN  \n",
       "10976  Eastern Time (US & Canada)  \n",
       "10977                         NaN  \n",
       "10978                         NaN  \n",
       "10979                         NaN  \n",
       "\n",
       "[10980 rows x 8 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.drop(columns=['retweet_count','tweet_coord','negativereason_gold','airline_sentiment_gold'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=list(x['airline_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=list(x['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "stop=set(stopwords.words('english'))\n",
    "punctuations=string.punctuation\n",
    "stop.update(list(punctuations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "def get_simple_pos_tag(tag):\n",
    "    if(tag.startswith('J')):\n",
    "        return wordnet.ADJ\n",
    "    elif(tag.startswith('V')):\n",
    "        return wordnet.VERB\n",
    "    elif(tag.startswith('N')):\n",
    "        return wordnet.NOUN\n",
    "    elif(tag.startswith('R')):\n",
    "        return wordnet.ADJ\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_review(words):\n",
    "    output_words=[]\n",
    "    for w in words:\n",
    "        if(w.lower() not in stop):\n",
    "            pos=pos_tag([w])\n",
    "            tag=get_simple_pos_tag(pos[0][1])\n",
    "            clean_word=lemmatizer.lemmatize(w,pos=get_simple_pos_tag(tag))\n",
    "            output_words.append(clean_word)\n",
    "    return output_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "document=[word_tokenize(doc) for doc in x_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train2=[clean_review(doc) for doc in document]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train3=[' '.join(doc) for doc in x_train2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using tfidf vectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "cv=TfidfVectorizer()\n",
    "X=cv.fit_transform(x_train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10980x12147 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 110529 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data=pd.read_csv('0000000000002747_test_twitter_x_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>569682010270101504</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zsalim03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir In car gng to DFW. Pulled over 1h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 18:15:50 -0800</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>569608307184242688</td>\n",
       "      <td>American</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sa_craig</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@AmericanAir after all, the plane didn‚Äôt land ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 13:22:57 -0800</td>\n",
       "      <td>College Station, TX</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id   airline airline_sentiment_gold      name  \\\n",
       "0  569682010270101504  American                    NaN  zsalim03   \n",
       "1  569608307184242688  American                    NaN  sa_craig   \n",
       "\n",
       "  negativereason_gold  retweet_count  \\\n",
       "0                 NaN              0   \n",
       "1                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0  @AmericanAir In car gng to DFW. Pulled over 1h...         NaN   \n",
       "1  @AmericanAir after all, the plane didn‚Äôt land ...         NaN   \n",
       "\n",
       "               tweet_created       tweet_location               user_timezone  \n",
       "0  2015-02-22 18:15:50 -0800                Texas  Central Time (US & Canada)  \n",
       "1  2015-02-22 13:22:57 -0800  College Station, TX  Central Time (US & Canada)  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline</th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>569682010270101504</td>\n",
       "      <td>American</td>\n",
       "      <td>zsalim03</td>\n",
       "      <td>@AmericanAir In car gng to DFW. Pulled over 1h...</td>\n",
       "      <td>2015-02-22 18:15:50 -0800</td>\n",
       "      <td>Texas</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>569608307184242688</td>\n",
       "      <td>American</td>\n",
       "      <td>sa_craig</td>\n",
       "      <td>@AmericanAir after all, the plane didn‚Äôt land ...</td>\n",
       "      <td>2015-02-22 13:22:57 -0800</td>\n",
       "      <td>College Station, TX</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>567879304593408001</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>DanaChristos</td>\n",
       "      <td>@SouthwestAir can't believe how many paying cu...</td>\n",
       "      <td>2015-02-17 18:52:31 -0800</td>\n",
       "      <td>CT</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>569757651539660801</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>rossj987</td>\n",
       "      <td>@USAirways I can legitimately say that I would...</td>\n",
       "      <td>2015-02-22 23:16:24 -0800</td>\n",
       "      <td>Washington, D.C.</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>569900705852608513</td>\n",
       "      <td>American</td>\n",
       "      <td>tranpham18</td>\n",
       "      <td>@AmericanAir still no response from AA. great ...</td>\n",
       "      <td>2015-02-23 08:44:51 -0800</td>\n",
       "      <td>New York City</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3655</th>\n",
       "      <td>570304244001193984</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>Anthony_Scerri</td>\n",
       "      <td>@USAirways Been stuck for 40+ minutes due to l...</td>\n",
       "      <td>2015-02-24 11:28:22 -0800</td>\n",
       "      <td>Astoria, NY</td>\n",
       "      <td>Quito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3656</th>\n",
       "      <td>567847737061941249</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>mttdprkr</td>\n",
       "      <td>@USAirways 4 hours... 4 hours... FOUR HOURS.  ...</td>\n",
       "      <td>2015-02-17 16:47:05 -0800</td>\n",
       "      <td>Vancouver, WA</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3657</th>\n",
       "      <td>567823564167192576</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>miaerolinea</td>\n",
       "      <td>Nice RT @VirginAmerica: The man of steel might...</td>\n",
       "      <td>2015-02-17 15:11:02 -0800</td>\n",
       "      <td>Worldwide</td>\n",
       "      <td>Caracas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3658</th>\n",
       "      <td>570273819287531520</td>\n",
       "      <td>American</td>\n",
       "      <td>GoldensPleasure</td>\n",
       "      <td>@AmericanAir Aww Thanks AA..DFW was on GMA up ...</td>\n",
       "      <td>2015-02-24 09:27:28 -0800</td>\n",
       "      <td>East Coast     CT.</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3659</th>\n",
       "      <td>569341769114128386</td>\n",
       "      <td>United</td>\n",
       "      <td>suntoshi</td>\n",
       "      <td>@united the lounge tells us they have no pillo...</td>\n",
       "      <td>2015-02-21 19:43:50 -0800</td>\n",
       "      <td>Bedford, Nh</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3660 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id         airline             name  \\\n",
       "0     569682010270101504        American         zsalim03   \n",
       "1     569608307184242688        American         sa_craig   \n",
       "2     567879304593408001       Southwest     DanaChristos   \n",
       "3     569757651539660801      US Airways         rossj987   \n",
       "4     569900705852608513        American       tranpham18   \n",
       "...                  ...             ...              ...   \n",
       "3655  570304244001193984      US Airways   Anthony_Scerri   \n",
       "3656  567847737061941249      US Airways         mttdprkr   \n",
       "3657  567823564167192576  Virgin America      miaerolinea   \n",
       "3658  570273819287531520        American  GoldensPleasure   \n",
       "3659  569341769114128386          United         suntoshi   \n",
       "\n",
       "                                                   text  \\\n",
       "0     @AmericanAir In car gng to DFW. Pulled over 1h...   \n",
       "1     @AmericanAir after all, the plane didn‚Äôt land ...   \n",
       "2     @SouthwestAir can't believe how many paying cu...   \n",
       "3     @USAirways I can legitimately say that I would...   \n",
       "4     @AmericanAir still no response from AA. great ...   \n",
       "...                                                 ...   \n",
       "3655  @USAirways Been stuck for 40+ minutes due to l...   \n",
       "3656  @USAirways 4 hours... 4 hours... FOUR HOURS.  ...   \n",
       "3657  Nice RT @VirginAmerica: The man of steel might...   \n",
       "3658  @AmericanAir Aww Thanks AA..DFW was on GMA up ...   \n",
       "3659  @united the lounge tells us they have no pillo...   \n",
       "\n",
       "                  tweet_created       tweet_location  \\\n",
       "0     2015-02-22 18:15:50 -0800                Texas   \n",
       "1     2015-02-22 13:22:57 -0800  College Station, TX   \n",
       "2     2015-02-17 18:52:31 -0800                   CT   \n",
       "3     2015-02-22 23:16:24 -0800     Washington, D.C.   \n",
       "4     2015-02-23 08:44:51 -0800        New York City   \n",
       "...                         ...                  ...   \n",
       "3655  2015-02-24 11:28:22 -0800          Astoria, NY   \n",
       "3656  2015-02-17 16:47:05 -0800        Vancouver, WA   \n",
       "3657  2015-02-17 15:11:02 -0800            Worldwide   \n",
       "3658  2015-02-24 09:27:28 -0800   East Coast     CT.   \n",
       "3659  2015-02-21 19:43:50 -0800          Bedford, Nh   \n",
       "\n",
       "                   user_timezone  \n",
       "0     Central Time (US & Canada)  \n",
       "1     Central Time (US & Canada)  \n",
       "2     Eastern Time (US & Canada)  \n",
       "3     Eastern Time (US & Canada)  \n",
       "4     Eastern Time (US & Canada)  \n",
       "...                          ...  \n",
       "3655                       Quito  \n",
       "3656  Pacific Time (US & Canada)  \n",
       "3657                     Caracas  \n",
       "3658  Central Time (US & Canada)  \n",
       "3659  Eastern Time (US & Canada)  \n",
       "\n",
       "[3660 rows x 7 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data.drop(columns=['retweet_count','tweet_coord','negativereason_gold','airline_sentiment_gold'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test=list(testing_data['airline_sentiment'])\n",
    "x_test=list(testing_data['text'])\n",
    "document_test=[word_tokenize(doc) for doc in x_test]\n",
    "x_test2=[clean_review(doc) for doc in document_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test3=[' '.join(doc) for doc in x_test2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=cv.transform(x_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3660x12147 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 34512 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf=RandomForestClassifier(random_state=0)\n",
    "clf.fit(X,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'negative', 'negative', ..., 'neutral', 'positive',\n",
       "       'negative'], dtype='<U8')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=list(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.savetxt(\"predictions_forest.csv\", y_pred,fmt = '%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                           class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': [100.0, 1000.0, 5000.0, 10000.0, 50000.0,\n",
       "                               100000.0],\n",
       "                         'gamma': [0.001, 0.0005, 0.0001, 0.005]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "clf=svm.SVC()\n",
    "grid={'C':[1e2,1e3,5e3,1e4,5e4,1e5],'gamma':[1e-3,5e-4,1e-4,5e-3]}\n",
    "abc=GridSearchCV(clf,grid)\n",
    "abc.fit(X,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=abc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"predictions_svm.csv\", y_test,fmt = '%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
